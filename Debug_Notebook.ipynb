{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcccf064-9424-42e4-be3b-6928b03fe013",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import hashlib\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from io import StringIO\n",
    "from datetime import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6a80e11-4dac-4aa5-b556-a49d2eeaa778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQS and S3 Clients\n",
    "sqs = boto3.client('sqs', region_name='us-east-1')\n",
    "s3 = boto3.client('s3', region_name='us-east-1')\n",
    "\n",
    "# Environment Variables (set in the Fargate task)\n",
    "# SQS_QUEUE_URL = os.getenv('SQS_QUEUE_URL')  # Queue URL\n",
    "SQS_QUEUE_URL = 'https://sqs.YOUR_REGION.amazonaws.com/794038211747/temperature_by_city'  # Queue URL\n",
    "OUTPUT_BUCKET_NAME = 'serempre-test'  # Output S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22da5cb6-0987-4523-8873-2571b91228c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_handled_file():\n",
    "    # Define source and destination file paths (keys)\n",
    "    source_key = 'raw/GlobalLandTemperaturesByMajorCity.csv'\n",
    "    destination_key = 'handled/GlobalLandTemperaturesByMajorCity.csv'\n",
    "    bucket_name = 'serempre-test'\n",
    "    \n",
    "    # Copy the file from the old location to the new location\n",
    "    s3.copy_object(\n",
    "        Bucket=bucket_name,\n",
    "        CopySource={'Bucket': bucket_name, 'Key': source_key},\n",
    "        Key=destination_key\n",
    "    )\n",
    "    \n",
    "    # Delete the original file\n",
    "    s3.delete_object(Bucket=bucket_name, Key=source_key)\n",
    "    print('done move handled file')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e61ba09-6dbd-4981-94ee-0438d14642ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_files_into_countries_upload_to_s3(csv_file):\n",
    "    # Insert data into s3\n",
    "    countries = csv_file['Country'].unique()\n",
    "    for country in countries:\n",
    "        if country == 'Côte D\\'Ivoire':\n",
    "            country_file = csv_file[csv_file['Country'].isin([country])]\n",
    "            country = re.sub(r\"Côte D\\'Ivoire\", \"cote_divoire\", country.lower())\n",
    "        else:\n",
    "            country_file = csv_file[csv_file['Country'].isin([country])]\n",
    "            country = re.sub(r\"\\s\", \"_\", country.lower())\n",
    "        csv_buffer = StringIO()\n",
    "        country_file.to_csv(csv_buffer, index=False)\n",
    "        s3.put_object(Bucket='serempre-test', Key=f\"transformed/{country}_temperature_by_city\", Body=csv_buffer.getvalue())\n",
    "    print('done split files into countries')\n",
    "\n",
    "\n",
    "def hash_long_lat(csv_file):\n",
    "    csv_file['Latitude'] = [hashlib.md5(str(val).encode('utf-8')).hexdigest() for val in csv_file['Latitude']]\n",
    "    csv_file['Longitude'] = [hashlib.md5(str(val).encode('utf-8')).hexdigest() for val in csv_file['Longitude']]\n",
    "    print('done hash long lat')\n",
    "    return csv_file\n",
    "\n",
    "\n",
    "def read_csv_from_s3(bucket: str, key: str) -> pd.DataFrame:\n",
    "    \"\"\"Read a CSV file from S3 and load it into a Pandas DataFrame.\"\"\"\n",
    "    obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "    file_content = obj['Body'].read().decode('utf-8')\n",
    "    csv_buffer = StringIO(file_content)\n",
    "    df = pd.read_csv(csv_buffer)\n",
    "    print('done read csv from s3')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3716a22d-ad8a-4e64-984b-620c610d9ee1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m key \u001b[38;5;241m=\u001b[39m records[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms3\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkey\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Download the file from S3\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mread_csv_from_s3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Process the CSV file\u001b[39;00m\n\u001b[1;32m     25\u001b[0m df \u001b[38;5;241m=\u001b[39m hash_long_lat(df)\n",
      "Cell \u001b[0;32mIn[4], line 27\u001b[0m, in \u001b[0;36mread_csv_from_s3\u001b[0;34m(bucket, key)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read a CSV file from S3 and load it into a Pandas DataFrame.\"\"\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m obj \u001b[38;5;241m=\u001b[39m s3\u001b[38;5;241m.\u001b[39mget_object(Bucket\u001b[38;5;241m=\u001b[39mbucket, Key\u001b[38;5;241m=\u001b[39mkey)\n\u001b[0;32m---> 27\u001b[0m file_content \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBody\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m csv_buffer \u001b[38;5;241m=\u001b[39m StringIO(file_content)\n\u001b[1;32m     29\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_buffer)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/botocore/response.py:99\u001b[0m, in \u001b[0;36mStreamingBody.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Read at most amt bytes from the stream.\u001b[39;00m\n\u001b[1;32m     95\u001b[0m \n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03mIf the amt argument is omitted, read all data.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m URLLib3ReadTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;66;03m# TODO: the url will be None as urllib3 isn't setting it yet\u001b[39;00m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(endpoint_url\u001b[38;5;241m=\u001b[39me\u001b[38;5;241m.\u001b[39murl, error\u001b[38;5;241m=\u001b[39me)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/response.py:567\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    564\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 567\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    569\u001b[0m         flush_decoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/urllib3/response.py:533\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buffer\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/http/client.py:488\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 488\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_safe_read\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m IncompleteRead:\n\u001b[1;32m    490\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/http/client.py:633\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[1;32m    627\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;124;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;124;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m amt:\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(data))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/ssl.py:1249\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1245\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1246\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1247\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1248\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/ssl.py:1105\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1106\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1107\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# def main():\n",
    "while True:\n",
    "    # Receive messages from SQS\n",
    "    response = sqs.receive_message(\n",
    "        QueueUrl=SQS_QUEUE_URL,\n",
    "        MaxNumberOfMessages=1,\n",
    "        WaitTimeSeconds=1\n",
    "    )\n",
    "    messages = response.get('Messages', [])\n",
    "    if not messages:\n",
    "        print(\"No messages in the queue.\")\n",
    "        continue\n",
    "\n",
    "    for message in messages:\n",
    "        try:\n",
    "            body = json.loads(message['Body'])\n",
    "            records = body['Records'][0]\n",
    "            bucket = records['s3']['bucket']['name']\n",
    "            key = records['s3']['object']['key']\n",
    "\n",
    "            # Download the file from S3\n",
    "            df = read_csv_from_s3(bucket, key)\n",
    "\n",
    "            # Process the CSV file\n",
    "            df = hash_long_lat(df)\n",
    "            split_files_into_countries_upload_to_s3(df)\n",
    "            move_handled_file()\n",
    "            print(\"done\")\n",
    "            # Delete message from queue after processing\n",
    "            sqs.delete_message(\n",
    "                QueueUrl=SQS_QUEUE_URL,\n",
    "                ReceiptHandle=message['ReceiptHandle']\n",
    "            )\n",
    "            print(f\"Processed and deleted message: {message['MessageId']}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing message: {e}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e008a033-36a3-4750-96f8-ddb70c6acc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import hashlib\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from io import StringIO\n",
    "from time import sleep\n",
    "\n",
    "# SQS and S3 Clients\n",
    "sqs = boto3.client('sqs', region_name='us-east-1')\n",
    "s3 = boto3.client('s3', region_name='us-east-1')\n",
    "\n",
    "# Environment Variables (set in the Fargate task)\n",
    "# SQS_QUEUE_URL = os.getenv('SQS_QUEUE_URL')  # Queue URL\n",
    "# OUTPUT_BUCKET_NAME = os.getenv('SQS_QUEUE_URL')  # Output S3 bucket\n",
    "SQS_QUEUE_URL = 'https://sqs.YOUR_REGION.amazonaws.com/794038211747/temperature_by_city'  # Queue URL\n",
    "OUTPUT_BUCKET_NAME = 'serempre-test'  # Output S3 bucket\n",
    "\n",
    "def split_files_into_countries_upload_to_s3(csv_file):\n",
    "    # Insert data into s3\n",
    "    countries = csv_file['Country'].unique()\n",
    "    for country in countries:\n",
    "        if country == \"Côte D'Ivoire\":\n",
    "            country_file = csv_file[csv_file['Country'].isin([country])]\n",
    "            country = re.sub(r\"Côte D'Ivoire\", \"cote_divoire\", country.lower())\n",
    "        else:\n",
    "            country_file = csv_file[csv_file['Country'].isin([country])]\n",
    "            country = re.sub(r\"\\s\", \"_\", country.lower())\n",
    "        csv_buffer = StringIO()\n",
    "        country_file.to_csv(csv_buffer, index=False)\n",
    "        s3.put_object(Bucket='serempre-test', Key=f\"transformed/{country}_temperature_by_city\", Body=csv_buffer.getvalue())\n",
    "\n",
    "\n",
    "def hash_long_lat(csv_file):\n",
    "    csv_file['Latitude'] = [hashlib.md5(str(val).encode('utf-8')).hexdigest() for val in csv_file['Latitude']]\n",
    "    csv_file['Longitude'] = [hashlib.md5(str(val).encode('utf-8')).hexdigest() for val in csv_file['Longitude']]\n",
    "    return csv_file\n",
    "\n",
    "\n",
    "def read_csv_from_s3(bucket: str, key: str) -> pd.DataFrame:\n",
    "    \"\"\"Read a CSV file from S3 and load it into a Pandas DataFrame.\"\"\"\n",
    "    obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "    file_content = obj['Body'].read().decode('utf-8')\n",
    "    csv_buffer = StringIO(file_content)\n",
    "    df = pd.read_csv(csv_buffer)\n",
    "    return df\n",
    "\n",
    "\n",
    "def move_handled_file(bucket_name, source_key, destination_key):    \n",
    "    # Copy the file from the old location to the new location\n",
    "    s3.copy_object(\n",
    "        Bucket=bucket_name,\n",
    "        CopySource={'Bucket': bucket_name, 'Key': source_key},\n",
    "        Key=destination_key\n",
    "    )\n",
    "    \n",
    "    # Delete the original file\n",
    "    s3.delete_object(Bucket=bucket_name, Key=source_key)\n",
    "\n",
    "\n",
    "# def main():\n",
    "while True:\n",
    "    # Receive messages from SQS\n",
    "    response = sqs.receive_message(\n",
    "        QueueUrl=SQS_QUEUE_URL,\n",
    "        MaxNumberOfMessages=1,\n",
    "        WaitTimeSeconds=1\n",
    "    )\n",
    "    messages = response.get('Messages', [])\n",
    "    if not messages:\n",
    "        print(\"No messages in the queue.\")\n",
    "        continue\n",
    "\n",
    "    for message in messages:\n",
    "        try:\n",
    "            body = json.loads(message['Body'])\n",
    "            records = body['Records'][0]\n",
    "            bucket = records['s3']['bucket']['name']\n",
    "            key = records['s3']['object']['key']\n",
    "            destination_key = 'handled/GlobalLandTemperaturesByMajorCity.csv'\n",
    "\n",
    "            # Download the file from S3\n",
    "            df = read_csv_from_s3(bucket, key)\n",
    "\n",
    "            # Process the CSV file\n",
    "            df = hash_long_lat(df)\n",
    "            split_files_into_countries_upload_to_s3(df)\n",
    "            move_handled_file(bucket, key, destination_key)\n",
    "            print(\"done\")\n",
    "            # Delete message from queue after processing\n",
    "            sqs.delete_message(\n",
    "                QueueUrl=SQS_QUEUE_URL,\n",
    "                ReceiptHandle=message['ReceiptHandle']\n",
    "            )\n",
    "            print(f\"Processed and deleted message: {message['MessageId']}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing message: {e}\")\n",
    "#         sleep(10)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd3d3ed-31ca-4bae-9ffa-bf93e7302a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
